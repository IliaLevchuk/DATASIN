{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04be9521",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0ccc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston \n",
    "from sklearn.model_selection import train_test_split\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47d6483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6f2d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = boston['data']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7ddc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = boston[\"feature_names\"]\n",
    "\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4f6192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston[\"DESCR\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae8ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d21e43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data, columns=feature_names)\n",
    "y = pd.DataFrame(target, columns=[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a53f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "980e5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f69dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aadefcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab72b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31d287cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d98349c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112260057484973"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87efeb5",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f879605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a4b7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators = 1000, max_depth = 12, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ca2564a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=12, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8d5e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9df854f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87472606157312"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf64e7b",
   "metadata": {},
   "source": [
    "### в данном случае вторая модель работает лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac48ae",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21c1377c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestRegressor in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestRegressor(ForestRegressor)\n",
      " |  RandomForestRegressor(n_estimators=100, *, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest regressor.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of classifying\n",
      " |  decision trees on various sub-samples of the dataset and uses averaging\n",
      " |  to improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"mse\", \"mae\"}, default=\"mse\"\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"mse\" for the mean squared error, which is equal to variance\n",
      " |      reduction as feature selection criterion, and \"mae\" for the mean\n",
      " |      absolute error.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `round(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=n_features`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, default=None\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 1.0 (renaming of 0.25).\n",
      " |         Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool, default=False\n",
      " |      whether to use out-of-bag samples to estimate\n",
      " |      the R^2 on unseen data.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0, 1)`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  base_estimator_ : DecisionTreeRegressor\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeRegressor\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_prediction_ : ndarray of shape (n_samples,)\n",
      " |      Prediction computed with out-of-bag estimate on the training set.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DecisionTreeRegressor, ExtraTreesRegressor\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  The default value ``max_features=\"auto\"`` uses ``n_features``\n",
      " |  rather than ``n_features / 3``. The latter was originally suggested in\n",
      " |  [1], whereas the former was more recently justified empirically in [2].\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
      " |         trees\", Machine Learning, 63(1), 3-42, 2006.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestRegressor\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  >>> X, y = make_regression(n_features=4, n_informative=2,\n",
      " |  ...                        random_state=0, shuffle=False)\n",
      " |  >>> regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  RandomForestRegressor(...)\n",
      " |  >>> print(regr.predict([[0, 0, 0, 0]]))\n",
      " |  [-8.32987858]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestRegressor\n",
      " |      ForestRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestRegressor:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict regression target for X.\n",
      " |      \n",
      " |      The predicted regression target of an input sample is computed as the\n",
      " |      mean predicted regression targets of the trees in the forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination :math:`R^2` of the\n",
      " |      prediction.\n",
      " |      \n",
      " |      The coefficient :math:`R^2` is defined as :math:`(1 - \\frac{u}{v})`,\n",
      " |      where :math:`u` is the residual sum of squares ``((y_true - y_pred)\n",
      " |      ** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true -\n",
      " |      y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it\n",
      " |      can be negative (because the model can be arbitrarily worse). A\n",
      " |      constant model that always predicts the expected value of `y`,\n",
      " |      disregarding the input features, would get a :math:`R^2` score of\n",
      " |      0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __annotations__ = {'_required_parameters': typing.List[str]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestRegressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3a8578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(model.feature_importances_, index=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a27b3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0851585e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "coef.plot(kind = \"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a607d3",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7413f67f",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/HP/Downloads/creditcard.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-4d3c43edd014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/HP/Downloads/creditcard.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/HP/Downloads/creditcard.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv ('C:/Users/HP/Downloads/creditcard.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30014d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c7db66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7addb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00075b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05540bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267df78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311139e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16d5bb87",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99230bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1bcf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keys=data[\"feature_names\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1225989",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"target_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data[\"target\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(data.data, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497db30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['target'] = data[\"target\"].astype(np.int64)\n",
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ec1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_corr=x.corr()\n",
    "x_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr = x_corr[\"target\"]\n",
    "high_corr = high_corr[np.abs(high_corr)>0.5].drop(\"target\", axis=0)\n",
    "high_corr=list(high_corr.index)\n",
    "high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c588c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee092c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in high_corr:\n",
    " x[i+\"_2\"]=x[i]**2\n",
    "x.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
